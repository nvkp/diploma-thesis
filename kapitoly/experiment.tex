\chapter{Experiment}

% TODO nějaký úvod, že ukazuju, jak je možné kombinovat OLAP a KG, co jsem použil za technologie, proč to dělám REPL

This section describes an experiment of mining associtation rules from RDF data compiled of statistical data structured by the Data Cube Vocabulary and facts pulled from the Wikidata data set that was performed as an practical part of this work. The statistical data come from two sources. The first one is the Czech Social Security Administration and the second one is the Czech Statistical Office. Analysis was performed using the Scala API of the reference implementation of the RDFRules algorithm. The following sectins describe how the available data had to be preprocced to give reasonable results in combination with KG data. The preprocessing was perfomed partly by the implementation's API itself, partly by performing SPARQL queries over the data. The described method can be taken inspiration from when performing similar analysis ie. association rule mining task over the multidimensional data merged with loosely structured graph data. 

\section{Czech Social Security Administration's Data Cubes}

Czech Social Security Administration (CSSA) is a czech public administration organtisation responsible for collecting social security premiums and contributions to the state employment policy. Since 2015 the organization publishes its statistical yearbook datasets and other (vocabularies, code lists and datasets containing data concerning the internal operation of the organization) in the form LOD and became of the first czech public institutions to do so. The yearbook statistical data sets are modelled using Data Cube Vocabulary. Their dimension values are represented by the SKOS vocabulary. The organization has published 73 datasets so far. All these datasets are downloadable as dumps\footnote{\href{http://data.cssz.cz/web/otevrena-data/katalog-otevrenych-dat}{http://data.cssz.cz/web/otevrena-data/katalog-otevrenych-dat}} or accesible througth a SPARQL endpoint\footnote{\href{http://data.cssz.cz/web/otevrena-data/sparql-query-editor/}{http://data.cssz.cz/web/otevrena-data/sparql-query-editor/}}. The CSSA's URIs are dereferenceable.

% project vše
% že tam jsou i CSV data a pro každý data set je stránka s popisem

The largest of the data cubes published is \verb|cssa-d:duchodci-v-cr-krajich-okresech|\footnote{https://data.cssz.cz/resource/dataset/duchodci-v-cr-krajich-okresech}. From now on it will be denoted as CSSA1. It contains \numprint{368118} observations structured spread over four dimensions: reference area\footnote{https://data.cssz.cz/ontology/dimension/refArea}, reference period\footnote{https://data.cssz.cz/ontology/dimension/refPeriod}, sex\footnote{https://data.cssz.cz/ontology/dimension/pohlavi} and pension kind\footnote{https://data.cssz.cz/ontology/dimension/druh-duchodu}. Observations are assigned three measures: the average amount of pension\footnote{https://data.cssz.cz/ontology/measure/prumerna-vyse-duchodu-v-kc}, the average age\footnote{https://data.cssz.cz/ontology/measure/prumerny-vek} and the number of persons\footnote{https://data.cssz.cz/ontology/measure/pocet-duchodcu}. Each observation is assigned only one measure.

\begin{figure}[h]
\begin{lstlisting}[language = turtle, caption={Example of an observation from CSSA1}, label={cssa1example},captionpos=b escapeinside={(*@}{@*)}]
@prefix qb: <http://purl.org/linked-data/cube#> .
@prefix cssa-om: <https://data.cssz.cz/ontology/measure/> .
@prefix cssa-d: <https://data.cssz.cz/resource/dataset/> .
@prefix cssa-od: <https://data.cssz.cz/ontology/dimension/> .

<https://data.cssz.cz/resource/observation/duchodci-v-cr-krajich-okresech/2017-12-31/prumerna-vyse-duchodu-v-kc/pk_srnvm/vc.35/m>
    a qb:Observation ;
    qb:dataSet cssa-d:duchodci-v-cr-krajich-okresech .
    qb:measureType cssa-om:prumerna-vyse-duchodu-v-kc ;
    cssa-od:druh-duchodu <https://data.cssz.cz/resource/pension-kind/PK_SRNVM_2010> ;
    cssa-od:pohlavi <https://data.cssz.cz/ontology/sdmx/code/sex-M> ;
    cssa-od:refArea <https://data.cssz.cz/resource/ruian/vusc/35>;
    cssa-od:refPeriod <https://data.cssz.cz/resource/reference.data.gov.uk/id/gregorian-day/2017-12-31>;
    cssa-om:prumerna-vyse-duchodu-v-kc 6622.0;
\end{lstlisting}
\end{figure}

In this particular data set there are \numprint{102} distinct values of the dimension of reference area: 14 regions (NUTS 3 administrative units, czech translation in singular nominative is \textit{kraj}) including Prague, 77 districts (\textit{okres}) also including Prague, 10 Prague districts (\textit{správní obvod}) and a value representing the state in total. Each entity representing a reference area is assigned an unique numerical identifier which corresponds to this area's identifier in the official Registry of Territorial Identification, Addresses and Real Estate (RTIAR) runned by the State Administration of Land Surveying and Cadastre (SALSC). RTIAR codes are reference codes by law, so it is obligatory for CSSA to use them and have them correct.

% SPARQL dotaz, ktery ukaze ty hodnoty ?

\begin{figure}[h]
\begin{lstlisting}[language = turtle, caption={Dereferenced proxy entity of the South Bohemian Region}, label={sbrexample},captionpos=b, escapeinside={(*@}{@*)}]
@prefix skos:  <http://www.w3.org/2004/02/skos/core#> .

<https://data.cssz.cz/resource/ruian/vusc/35>
    a <https://data.cssz.cz/ontology/ruian/Vusc> , skos:Concept ;
    <http://www.w3.org/2002/07/owl#sameAs> <https://linked.cuzk.cz/resource/ruian/vusc/35> ;
    skos:inScheme  <https://data.cssz.cz/resource/ruian/ConceptScheme> ;
    skos:notation "VC.35" ;
    skos:prefLabel "(*@Jihočeský kraj@*)" .
\end{lstlisting}
\end{figure}

There are official URIs of this registry but CSSA datasets do not used them directly. The entities for the dimension of reference area and other dimensions in the dataset CSSA1 and all other data sets of CSSA with the dimension of reference area work as so-called \textit{proxy entities}. This means that instead of using the original code list item URIs directly as objects in the RDF triples,  it uses their equivalents defined in the internal code lists. These equivalents are connected to the original URI by the \verb|owl:sameAs| statement. These proxies can then contain data specific to CSSA e.g. labels. Another advantage of this is, that these URIs are dereferenceable to the CSSA domain and their versioning is under the control of CSSA and they can be easily redirect to a different equivalent code list. Previously the proxy entities of the reference area were directed to the unofficial transformation of the Opendata.cz initiative\footnote{\href{https://linked.opendata.cz/dataset/cz-ruian}{https://linked.opendata.cz/dataset/cz-ruian}}.

Another dimension whose values work as proxy entities is the dimension of reference period. This dimension divides the observations into one year intervals. This applies to all other CSSA data cubes containg the reference period dimension. The data set vary in the overall covered period. The last covered year of all data sets is the year 2019. The entities link to the \verb|data.gov.uk| Time Intervals\footnote{\href{http://old.datahub.io/dataset/data-gov-uk-time-intervals}{http://old.datahub.io/dataset/data-gov-uk-time-intervals}} OWL ontology. Usage of this entities is, however, not unified. In some data sets intervals are assigned an entity representing a year, in other they are assigned an entity representing the last day of the corresponding year. All of them are, however, representing a period of a whole year.

\begin{figure}[h]
\begin{lstlisting}[language = turtle, caption={Dereferenced proxy entity of the year 2017}, label={gd2017example},captionpos=b, escapeinside={(*@}{@*)}]
@prefix skos:  <http://www.w3.org/2004/02/skos/core#> .

<https://data.cssz.cz/resource/reference.data.gov.uk/id/gregorian-year/2017>
    a skos:Concept ;
    <http://www.w3.org/2002/07/owl#sameAs> <http://reference.data.gov.uk/id/gregorian-year/2017> ;
    skos:inScheme <https://data.cssz.cz/ontology/years/YearsScheme> ;
    skos:notation "2017" ;
    skos:prefLabel "2017" .
\end{lstlisting}
\end{figure}

The CSSA1 dataset uses two distinct schemes for the pension kinds, because in 2010, the official categorization of pensions was changed in the czech legislation. Only the observations assigned to year 2008 are divided according to the old pension scheme. All other year's observations correnspond to the new pension scheme. So one can not simply multiply the numbers of distinct values for each dimension and the number of measures to get the total number of observations for this particular cube. The URIs of both pension kind schemes are suffixed either by \verb|_2008| (31 of them) for the old scheme or \verb|_2010| (37 of them) for the new scheme. Not all entities correspond to a particular kind of pension. Some of them represent an aggregation over related pension kinds or simply an aggregation over all of the pension kinds.

\begin{figure}[h]
\begin{lstlisting}[language = turtle, caption={Dereferenced pension kind}, label={pkexample},captionpos=b, escapeinside={(*@}{@*)}]
@prefix skos:  <http://www.w3.org/2004/02/skos/core#> .

<https://data.cssz.cz/resource/pension-kind/PK_SRNVM_2010>
    a <https://data.cssz.cz/ontology/pension-kinds/PensionKind> , skos:Concept ;
    skos:altLabel "SRNVM"@cs ;
    skos:exactMatch <https://data.cssz.cz/resource/pension-kind/PK_SRNVM> ;
    skos:inScheme <https://data.cssz.cz/ontology/pension-kinds/PensionKindScheme_2010> ;
    skos:notation "PK_SRNVM" ;
    skos:prefLabel "(*@Starobní důchod SRN vyplácený v souběhu s vdoveckým důchodem@*)"@cs .
\end{lstlisting}
\end{figure}

The dimension of sex consists of three distinct values: dimension of male pension, dimension of female pensions and its total. The values are proxy entities linking to the SDMX representations of sexes\footnote{\href{http://purl.org/linked-data/sdmx/2009/code}{http://purl.org/linked-data/sdmx/2009/code}}

\section{Czech Statistical Office's Data Cubes}

The Czech Statistical Office (CZSO) is the main public organization responsible for collecting and analyzing statistical data in the Czech Republic. This organization is for example responsible for the state's census. Data about demography, economics, education, health care etc. are made availabe on the organization's website\footnote{\href{https://vdb.czso.cz/vdbvo2/faces/en/index.jsf?page=uziv-dotaz}{https://vdb.czso.cz/vdbvo2/faces/en/index.jsf?page=uziv-dotaz}} in a form of interactive spreadsheet builder. Thanks to the Opendata.cz initiative this data sets are made available as LOD modelled by the Daca Cube Vocabulary in the initiative's catalogue. The data is also hosted as a SPARQL endpoint\footnote{\href{http://linked.opendata.cz/sparql}{http://linked.opendata.cz/sparql}}. 8 of these data sets have a dimension of reference period. Each data set’s dump file can be downloaded from the catalouge\footnote{The download link URLs are, however, broken and return HTTP status code 404. To get the dump file, word \textit{dumps} has to be substituted with word \textit{soubor} (czech word for \textit{file}). For example, the dump file of the data set \textbf{czso-job-applicants} is available at \href{https://linked.opendata.cz/soubor/czso-job-applicants.trig}{https://linked.opendata.cz/soubor/czso-job-applicants.trig}}.

\begin{figure}[h]
\begin{lstlisting}[language = turtle, caption={Example of an observation from the CZSO data sets}, label={turtleexample},captionpos=b escapeinside={(*@}{@*)}]
@prefix qb: <http://purl.org/linked-data/cube#> .
@prefix czso: <http://data.czso.cz/ontology/> .

<http://data.czso.cz/resource/observation/job-applicants-and-unemployment-rate/CZ0513/2009-12-31/T> a qb:Observation ;
    czso:refArea <http://ruian.linked.opendata.cz/resource/okresy/3505> ;
    czso:refPeriod <http://reference.data.gov.uk/id/gregorian-day/2009-12-31> ;
    czso:sex sdmx-code:sex-T ;
    czso:neumisteniUchazeciOZamestnani 9692.0 ;
    czso:dosazitelniNeumisteniUchazeciOZamestnani 9528.0 ;
    czso:podilNezamestnanych 7.92 ;
    czso:pocetVolnychMist 569.0 ;
    qb:dataSet <http://data.czso.cz/resource/dataset/job-applicants-and-unemployment-rate> .
\end{lstlisting}
\end{figure}

Observations in CZSO data cubes are assigned multiple measures. Their URIs are not dereferenceable. Their dimension value URIs do not work as proxy entities. The dimension of reference area uses entities of an above-mentioned initiative's unofficial RTIAR transformation\footnote{\href{https://linked.opendata.cz/dataset/cz-ruian}{https://linked.opendata.cz/dataset/cz-ruian}} with its own SPARQL endpoint\footnote{\href{https://ruian.linked.opendata.cz/sparql}{https://ruian.linked.opendata.cz/sparql}}. The measured values relate to regions and district. They do not contain observations related to the whole state. The proxy entities of the reference area dimension values for the CSSA data sets previously linked to this code list. 

For time intervals representation the CZSO data cubes also use the the \verb|data.gov.uk| Time Intervals OWL ontology. They only do so directly unlike the CSSA data cubes. The data cubes vary their time span. The earliest recorded values are for the year 2005. The latest values are for the year 2013. There are two data sets that contain values for both the earliest and latest year mentioned meaning they cover a period of 9 years: \textbf{czso-deaths-by-selected-causes-of-death}\footnote{\href{https://linked.opendata.cz/dataset/czso-deaths-by-selected-causes-of-death}{https://linked.opendata.cz/dataset/czso-deaths-by-selected-causes-of-death}} and \textbf{czso-job-applicants-and-unemployment-rate}\footnote{\href{https://linked.opendata.cz/dataset/czso-job-applicants-and-unemployment-rate}{https://linked.opendata.cz/dataset/czso-job-applicants-and-unemployment-rate}}

Just as with the CSSA data cubes, some of the CZSO data cubes contain the dimension of sex consisting of three distinct values: dimension of male pension, dimension of female pensions and its total. The values used are the SDMX representations of sexes themselves.

\section{Wikidata}

Wikidata data set contains data about political representation of countries, their administrative areas and municipalities. For the purposes of this experiment, such data concerning the Czech Republic was extracted from the data set. In the Czech Republic, regions and municipalities\footnote{Not districts though.} are being assigned a government that emerges from elections. In Wikidata data set, there exist records of who was or still is head of this local government, including the head of the state government. Records of these \textit{head of government} roles are given a time period of validity of this role by stating the date of this role's start and optionally the end of this role when it is not a current area government head anymore. For the persons who hold or held the office, the affiliation to a political party is stated in the data also with the start and end date of this affiliation. The entities of the political parties are assigned their political alignment (left, center, far-right etc.). In the sample of Wikidata data set's content below it is stated that since 2008 till 2016 the head of the government of the South Moravian Region was Michal Hašek who since 1998 is a member of the Czech Social Democratic Party, which has the centre-left political alignment.

\begin{figure}[h]
\begin{lstlisting}[language = turtle, caption={Description of XXX (Source: author)}, label={wdhasekexample},captionpos=b, escapeinside={(*@}{@*)}]
@prefix wd: <http://www.wikidata.org/entity/> .
@prefix p: <http://www.wikidata.org/prop/> .

wd:Q192697 rdfs:label "South Moravian Region"@en ;
    p:P6 [ p:P6 wd:Q6835752 ; p:P580 "2008-11-21T00:00:00Z" ; p:P582 "2016-11-16T00:00:00Z" ] .

wd:Q6835752 rdfs:label (*@"Michal Hašek"@*)@en ;
    p:P102 [ p:P102  wd:Q341148 ; p:P580 "1998-01-01T00:00:00Z" ] .

wd:Q341148 rdfs:label "Czech Social Democratic Party"@en ;
    p:P1387 [ p:P1387 wd:Q737014 ] .

wd:Q737014 rdfs:label "centre-left"@en .
\end{lstlisting}
\end{figure}

When adequately preprocced, this data can be utilized to find relations of statistical data described in the data cubes of CSSA and CZSO and the political cycle in the country. For example a rule can be found that states, that if in any year, the head of the Czech Republic's government was a member of a left-leaning policital party, the pension expenses for one-off allowance to pensions were above average. A query that extracts this data from the Wikidata's SPARQL endpoint is listed in \ref{wdextract}. This data, however, cannot be used for mining such rules yet. Measures in the data cubes are recorded on year to year bases. For the governmental roles and political affiliations it is only know the start date and end date. It is necessary to transform these triples into set of triples stating that a governmental role or the policital affiliation \textit{applies} for a certain year. The edge years are a bit tricky because the role or the membership was not valid for the whole year it started or ended. To facilitate the query and to generate more triples I decided to generate the triples for the edge years as well. The SPARQL query that constructs the \textit{appliesToRefPeriod} triples from the extracted data is listed in \ref{wdapplies}. The triples stating the start dates and end dates are no longer needed and do not have to be loaded into the RDFRules mining task.

The triples with predicates of \verb|p:P582| and \verb|p:P580| are no longer needed and are filtered out during the preproccesing. That will leave the data with \numprint{24410} distinct triples.

\section{YAGO Triples}

Triples concerning the entitities of reference areas in the examined data cubes can also be found in the YAGO\footnote{\href{https://yago-knowledge.org/}{https://yago-knowledge.org/}} dataset, which extracts facts about real world entities from various sources (Wikipedia, GeoNames, WordNet etc.). For a change unlike with the Wikidata dataset, for this experiment the needed triples are not extracted according to a rigidly structured CONSTRUCT queries but with loose DESCRIBE queries returning all triples concerning the seeked entities. The used queries\footnote{\href{https://github.com/nvkp/diploma-thesis-code/tree/master/data/yago}{https://github.com/nvkp/diploma-thesis-code/tree/master/data/yago}} extract the triples containing the reference areas themselves, the entities appearing in the triples together with the reference area entities (\textit{hop~1}) and the entities appearing in the triples of those entities (\textit{hop 2}). YAGO's public SPARQL endpoint's web interface\footnote{\href{https://yago-knowledge.org/sparql}{https://yago-knowledge.org/sparql}} has trouble handling the volume of the triples returned in the latter mentioned queries so one is better off quering the endpoint directly through a HTTP client.

Both districts and regions of the Czech Republic have their class\footnote{\href{http://yago-knowledge.org/resource/Districts\_of\_the_Czech\_Republic}{http://yago-knowledge.org/resource/Districts\_of\_the\_Czech\_Republic}}\footnote{\href{http://yago-knowledge.org/resource/Regions\_of\_the\_Czech\_Republic}{http://yago-knowledge.org/resource/Regions\_of\_the\_Czech\_Republic}} of which they are subclass in the YAGO dataset so the needed triples are easy to query. Total of \numprint{2992361} distinct triples was extracted, containing data about persons connected to the areas, geographical information about the areas (for example which region contains which district) etc.

\begin{figure}[h]
\begin{lstlisting}[language = turtle, caption={Example of the Extracted YAGO Triples (Source: author)}, label={yagoexample},captionpos=b, escapeinside={(*@}{@*)}]
@prefix schema: <http://schema.org/> .
@prefix yago: <http://yago-knowledge.org/resource/> .

yago:Prague a yago:Capital_city .
yago:Josef_Ji(*@ří@*)_Stankovsk(*@ý@*)_Q12026167 schema:deathPlace yago:Prague .
yago:What_the_Old_Man_Does_is_Always_Right_Q13564487 schema:translator yago:Josef_Ji(*@ří@*)_Stankovsk(*@ý@*)_Q12026167
\end{lstlisting}
\end{figure}

Around 62\% of the extracted triples are not relevant for the performed tasks. Their objects are literals (\verb|rdfs:label|, \verb|rdfs:comment| and \verb|schema:alternateName|) or image URLs (\verb|schema:image|). These triples are filtered out before the index data structure is constructed.

\section{Filtering the Observations}

The values for the city of Prague are duplicated. The city is assigned an entity both as a region and as a district. The administrative area of the Czech Republic's capital is given a special status by the Act No. 131/2000 Coll., on the Capital City of Prague and does not in fact fall into neighter of those categories. Nonetheless, Prague is assigned an identifier both as a district (\numprint{3100}) and as a region (\numprint{19}) in the RTIAR registry. When it comes to total population of the area (\numprint{1324227} as of 2020), it is comparable to other czech regions. The least populated is the Karlovy Vary Region with around \numprint{300000} inhabitants and the most populated: the Central Bohemian Region has around \numprint{1300000} inhabitants. Its surface area is on the other hand comparable with the districts. As the statistics about pensioners are certainly more correlated with the population rather than the surface area, the observation allocated to the dimension value of Prage as being district would be filtered out to maintain the commensurability along values measured for districts (see \ref{cssaSlicing}).

I also chose to filter out all observations regarding year 2008. For 2008 the pension kinds are structured according to a different scheme than any other year and it is hard to assume compatibility for the URIs that only differ in the year's suffix. 2008 scheme contains penkind kinds that 2010 does not end vice versa. It could be possible to just cut the cube so that the year's 2008 become one cube and the other years the other one, but a cube concerning only one reference period has not got much value. Both filters can be performed in a single SPARQL query. In the CSSA1 data set, discarting the Prague as a District entity removes \numprint{3609} observations. The year 2008 contained \numprint{28458} observations. \numprint{336330} observations are contained in the query's result making up 91,4\% of the unfiltered data set.

\begin{figure}[h]
\begin{lstlisting}[language = SPARQL, caption={SPARQL query to filter the CSSA1 data set (Source: author)}, label={sparqlexample},captionpos=b escapeinside={(*@}{@*)}]
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>
PREFIX qb: <http://purl.org/linked-data/cube#>
PREFIX cssa-d: <https://data.cssz.cz/resource/dataset/>
PREFIX cssa-od: <https://data.cssz.cz/ontology/dimension/>
PREFIX cssa-rd: <https://data.cssz.cz/resource/ruian/okresy/>
PREFIX cssa-op: <https://data.cssz.cz/ontology/pension-kinds/>

CONSTRUCT {
    ?observation ?p ?o
} 
WHERE {
    GRAPH cssa-d:duchodci-v-cr-krajich-okresech {
        ?observation qb:dataSet cssa-d:duchodci-v-cr-krajich-okresech ;
            cssa-od:druh-duchodu ?druh ;
            ?p ?o .
        NOT EXISTS {
            ?observation cssa-od:refArea cssa-rd:3100 .
        }
     }
     GRAPH cssa-d:pomocne-ciselniky {
        ?druh skos:inScheme cssa-op:PensionKindScheme_2010 .
     }
}
\end{lstlisting}
\end{figure}

\section{Slicing the Cubes\label{cssaSlicing}}

It is in part aimed to mine rules, in which the head atom's predicate is one of the cube's measures. In order to ensure, that such rules can achieve a reasonable support, the numerical values at the position of object in the measure triples have to be discretized and replaced by intervals. Irrespective to a chosen discretization approach, it is inadmissible to discretize values belonging to different disproportionate contexts. For example, we cannot create intervals for the number of pensioners from values measured for both regions and districts together. A district is a lower administrative unit. It belongs to a lower level in the concept hierarchy and it is assumed that its numbers of pensioners are of a different order of magnitude than those for regions or for the whole state. Same applies for values of dimensions sex and pension kind of the described data set. The values of the reference period represent even time intervals so the commensurability is assumed.

One way to solve is to slice a preprocessed cube having disproportionate dimension values into a set of smaller subcubes, in which the dimension values belong to the same level of a concept hierarchy. Measured values can be then discretized into intervals in each subcube separately. Number of subcubes that the main cube has to be divided into depends on the number dimensions and the number of levels in each dimension's hierarchies. Also when the commensurability cannot be expected among dimension values on the same level of their hierarchy, it is a good idea to \textit{make a cut} for each dimension value. For example, the dataset \verb|cssa-d:vydaje-na-duchody-v-cr|\footnote{\href{https://data.cssz.cz/resource/dataset/vydaje-na-duchody-v-cr}{https://data.cssz.cz/resource/dataset/vydaje-na-duchody-v-cr}} capturing costs on pensions in the Czech Republic by year and kind of pension contains 10 distinct values of the dimension of pension kind (not considering the scheme used only for year 2008). The cube would have to be divided into 10 subcubes for each value of the pension kind dimension. The CSSA1 data set would have to be divided into 222 subcubes. It has 37 pension kinds. Dimension of sex has two hierarchy levels: each sex and total. The dimension of reference area is considered to have 3 hierarchy levels: State's total, regions and Prague districts combined with the regional districts since they are comparable in number of inhabitants.

$$
37 \times 2 \times 3 = 222\hspace{0.4em}subcubes
$$

The construction of a subcube from a \textit{master} cube can be performed by a SPARQL CONSTRUCT query. An example of such query is shown in the listing \ref{sparqlcutexample}. This query filters the triples of the CZSO data cube \textbf{czso-job-applicants-and-unemployment-rate} to create a smaller cube of statistics about job applicants and unemployment rate for districts by sex. Notice how the reference area values corresponding to districts are distinguished. After the reference area values are linked (see \ref{linking}) to their CSSA counterparts, the ontology provided with the CSSA data sets can be reused.

\begin{figure}[h]
\begin{lstlisting}[language = SPARQL, caption={SPARQL query to create a subcube (Source: author)}, label={sparqlcutexample},captionpos=b escapeinside={(*@}{@*)}]
PREFIX qb: <http://purl.org/linked-data/cube#>
PREFIX sdmx-c: <http://purl.org/linked-data/sdmx/2009/code#>
PREFIX czso: <http://data.czso.cz/ontology/>
PREFIX czso-rd: <http://data.czso.cz/resource/dataset/>
PREFIX cssa-rd: <https://data.cssz.cz/resource/dataset/>
PREFIX cssa-or: <https://data.cssz.cz/ontology/ruian/>
PREFIX owl: <http://www.w3.org/2002/07/owl#>
    
CONSTRUCT { ?observation ?p ?o } 
WHERE { 
    GRAPH czso-rd:job-applicants-and-unemployment-rate {
        ?observation qb:dataSet czso-rd:job-applicants-and-unemployment-rate ;
            ?p ?o ;
            czso:refArea ?refAreaCZSO .
        NOT EXISTS {
            ?observation czso:sex sdmx-c:sex-T .
        }             
     }
    ?refAreaCSSZ owl:sameAs   ?refAreaCZSO.
    GRAPH cssa-rd:pomocne-ciselniky { ?refAreaCSSZ a cssa-or:Okres }
}
\end{lstlisting}
\end{figure}

For every subcube a similar query has to be created and performed over the master cube. For a cube that has to be divided into a small number of subcubes it is plausible to write (and save it for the documentation and repeatability purposes) and perform these queries manually. But there are cubes for which this would involve an hours long work. At the same time, it is an trivial activity that can easily be automated. For this preproccesing step for the CSSA1 dataset, a Scala script was written that creates 222 distinct SPARQL queries that construct 222 subcubes, saves each query to a text file and also creates a shell script that triggers all queries and saves a result of each query to a distinct file in the turtle format. The script is listed in \ref{scalascript}. This, however, still requires writing such script for each preprocced data cube and solve the problem of a time consuming resolution of the queries.


% že jsem řezal SPARQLem a ne RDFRules API, do ní už šly nařezané kostky

% že se musel potom upravit triply qb:dataSet object

\section{Linking\label{linking}}

In order to find rules describing relations across multiple sources (meaning data cubes of CZSO, data cubes of CSSA and Wikidata triples) the entities either have to be assigned the same URIs or to be connected by the \verb|owl:sameAs| statements. The shared dimensions of the CSSA and CZSO data cubes are the reference area, reference period and sex. The dimension values URIs used for these dimensions differ not only institution from institution but also data cube from data cube from the same institution (In the CSSA data cubes, reference period is represented by an entity of a year and of the last day of the year as well). Linking of equivalent dimension values of the three dimensions is done by creating \verb|owl:sameAs| statements.

\subsection{Sex Dimension Values}

It was already mentioned that the CSSA data cubes use proxy entities linking to the SDMX representations of sexes, whereas the CZSO data cubes use these representations directly. So the linking statements are already provided with the CSSA code list file. To extract these very triples, the query listed below can be used. These triples can be than loaded into a mining task involving mining from data cubes contain the dimension of sex instead of loading the whole code list file.

\begin{figure}[h]
\begin{lstlisting}[language = SPARQL, caption={Linking the sex dimension values}, label={sexlinkextract},captionpos=b, escapeinside={(*@}{@*)}]
PREFIX owl: <http://www.w3.org/2002/07/owl#>

CONSTRUCT { ?cssaSex owl:sameAs ?sdmxSex }
WHERE {
    GRAPH <https://data.cssz.cz/resource/dataset/pomocne-ciselniky> {
        ?cssaSex a <https://data.cssz.cz/ontology/sdmx/code/Sex> ; owl:sameAs ?sdmxSex
    }
}
\end{lstlisting}
\end{figure}

\subsection{Reference Periods}

In CSSA data cubes, values from two concept schemes are used for representing the year intervals: a years scheme and a days scheme. The entities in the schemes are proxy entitities linking to the \verb|data.gov.uk| Time Intervals ontology. CZSO data cubes use the ontology's day scheme concepts directly. That means that every year is represented by three distinct URIs in the data cubes so two \verb|owl:sameAs| statements are required for each year. A query was written that generates theses statements for every year entity in the CSSA code list:

\begin{figure}[h]
\begin{lstlisting}[language = SPARQL, caption={Linking the reference periods}, label={sexlinkextract},captionpos=b, escapeinside={(*@}{@*)}]
PREFIX owl: <http://www.w3.org/2002/07/owl#>
PREFIX skos: <http://www.w3.org/2004/02/skos/core#>
    
CONSTRUCT {
    ?cssaYear owl:sameAs  ?cssaDay .
    ?cssaYear owl:sameAs ?dataGovDay .
    ?cssaDay owl:sameAs ?dataGovDay .
}  
WHERE {
    GRAPH <https://data.cssz.cz/resource/dataset/pomocne-ciselniky> {
        ?cssaYear skos:inScheme <https://data.cssz.cz/ontology/years/YearsScheme>
        BIND (REPLACE(str(?cssaYear),".*(\\d{4})","$1") as ?cssaYearValue)
        ?cssaDay skos:inScheme <https://data.cssz.cz/ontology/days/DaysScheme>
        FILTER (REGEX(str(?cssaDay), ".*day.*12-31"))
        BIND (REPLACE(str(?cssaDay),".*(\\d{4})-12-31","$1") as ?cssaDayValue)
        ?cssaDay owl:sameAs ?dataGovDay
        FILTER (?cssaYearValue = ?cssaDayValue)
    }
}
\end{lstlisting}
\end{figure}

\subsection{Reference Areas}

The proxy entities of the reference area in CSSA data set used to link to the same entities that are used by the CZSO data sets. This linking is no longer present in the CSSA's code list but can be retrieved from the Opendata.cz's SPARQL endpoint. The query listed below returns 114 linking triples for all districts (including the Prague district entity), all regions (including Prague), Prague districts and the entity of the whole state. The linking with the Wikidata's entities had to be performed manually.

\begin{figure}[h]
\begin{lstlisting}[language = SPARQL, caption={Linking the reference periods}, label={refarealinking},captionpos=b, escapeinside={(*@}{@*)}]
PREFIX owl: <http://www.w3.org/2002/07/owl#>

CONSTRUCT {
    ?cssaArea owl:sameAs ?odArea
}
WHERE {
    ?cssaArea a ?class ; owl:sameAs ?odArea .
    FILTER (?class IN (
        <https://data.cssz.cz/ontology/ruian/Okres>,
        <https://data.cssz.cz/ontology/ruian/Vusc>,
        <https://data.cssz.cz/ontology/ruian/SpravniObvod>,
        <https://data.cssz.cz/ontology/ruian/Stat>
        )
    )
}
\end{lstlisting}
\end{figure}

\section{Discretization\label{discretization}}

The RDFRules implementation provides discretization functionality. The discretization tasks are, howerever, federated to the implemented discretization algorithms of the EasyMiner-Discretization library\footnote{\href{https://github.com/KIZI/EasyMiner-Discretization}{https://github.com/KIZI/EasyMiner-Discretization}}. The equifrequent and the equisize (TODO změň) discretization were chosen for the purposes of this experiment. The count of intervals that is set to be created from the set of measured values while performing the equifrequent discretization determines how many a which rules are generated by the RDFRules algorithm. If the the values are discretized into a small number of intervals, more rules with should be geenerated but the measure values become coarse and information is lost. If creating too many intervals, more specific rules should be found but they happen to have lower support. When performing the equisize discretization, coarser rules are found for the intervals created for a higher support. 

To avoid guessing, which number of intervals and which minimal support suits best the preprocessed data, multiple discretizations were performed with different parameters for both discretization algorithms. The minimal support thresholds were calculated as absolute numbers of various percentages of observations in the discretized cubes. As it was already mentioned, the preprocessed cube has to be cut into subcubes with commensurable observations, measures in theses subcube have to be discretized separately and only after that the triples can be merged and performed the mining tasks on.

That means that the number of overall measurements multiplies by the number of distinct discretizations. A situation has to be avoided, when the instantiations of variable representing observations are involving observations not only from various subcubes. The approach to solve this problem no matter how many measures are assigned to each observation will be shown on a sample of data below.

\begin{figure}[h]
\begin{lstlisting}[language = turtle, caption={Observation example}, label={discsample},captionpos=b escapeinside={(*@}{@*)}]
@prefix qb: <http://purl.org/linked-data/cube#> .

<o1> qb:dataSet <original-dataset> ;
    <dimension1> <dimension1value1> ; <dimension2> <dimension2value1> ;
    <measure1> 25000 ;
    <measure2> 3 .

<o2> qb:dataSet <original-dataset> ;
    <dimension1> <dimension1value2> ; <dimension2> <dimension2value2> ;
    <measure1> 10000 ;
    <measure2> 10 .
 \end{lstlisting}
\end{figure}

Each application of a discretization algorithm will create a new measurement triple for each measure and observation with an object of the assigned interval based on the discretization algorithm and the parameter. The objects in triples assigning the observations to a data set will be changed to point to the particular subcube. In the example below two discretizations for each measure were performed on the two observations. In the example the same pair of discretizations were performed on the two distinct measures, but that does not have to be so. Assigning multiple triples of the same measure is fine as far as the measure is differently discretized. 

\begin{figure}[h]
\begin{lstlisting}[language = turtle, caption={Discretization example}, label={discsample},captionpos=b escapeinside={(*@}{@*)}]
@prefix qb: <http://purl.org/linked-data/cube#> .
        
<o1> qb:dataSet <subcube1> ;
    <dimension1> <dimension1value1> ; <dimension2> <dimension2value1> ;
    <measure1> <subcube1_ef3_measure1_3>, <subcube1_es10_measure1_2> ;
    <measure2> <subcube1_ef3_measure2_2>, <subcube1_es10_measure2_1> .

<o2> qb:dataSet <subcube2> ;
    <dimension1> <dimension1value2> ; <dimension2> <dimension2value2> ;
    <measure1> <subcube2_ef3_measure1_3> , <subcube2_es10_measure1_2> ;
    <measure2> <subcube2_ef3_measure2_1> ,<subcube2_es10_measure2_1> .
\end{lstlisting}
\end{figure}

The discretized subcubes can be than merged into a singe data set a be performed mining tasks on. In each rule it has to be ensured, that the set of observations is limited to a certain subcube. For each cube in a rule the body of a rule has to contain an atom of a pattern \verb|(?o qb:dataSet AnyConstant)|. 

An alternative to creating subcubes based on the concept hierarchy in the master cube's dimensions is to use an unsupervised clustering algorithm (eg. k-means) to divide the observations into subcubes based on the proximity of their measures. After that the workflow is the same, the measures are discretized in the generated subcubes separately and than the subcubes are merged. But this brings two problems when used for the RDFRules algorithm.

\begin{enumerate}
    \item There is no clear interpretation of the generated subcubes, because their observation can belong to different levels of the concept hierarchy in a dimension. Unlike with the previous approach where a generated subcube could be described as for example \textit{Population in districts by age category}.
    \item For each distinct measure in the master cube a set of subcubes would have to be generated. So if the observations are assigned multiple measures (as the CZSO observations are) the number of observations would multiple with the number of measures and the observation URIs would have to be distinguished as one observation cannot be assigned to multiple data sets by the \verb|qb:dataSet| triple.
\end{enumerate}

\section{Mining Tasks}

The source codes of the performed experiment are available in repository on github\footnote{\href{https://github.com/nvkp/diploma-thesis-code}{https://github.com/nvkp/diploma-thesis-code}} in the directory \textit{notebooks} in a form of jupyter\footnote{\href{https://jupyter.org/}{https://jupyter.org/}} notebooks. A Scala kernel for jupyter (eg. \textit{almond.sh}\footnote{\href{http://almond.sh/}{http://almond.sh/}}) has to be install in order to execute the code directly from the notebooks (see \textit{README.md}). Some of the notebooks are dedicated to preproccesing of a particular data set and other contain the performed mining tasks. In the preproccesing notebooks the preprocced data set is exported to a text file in the \textit{Turtle} format and also saved into a cache file from which the data set is loaded into memory before a mining task.  Github strictly enforces 100 MB size limit for each file so the cache files and \textit{Turtle} files are not pushed into the repository. In order to run the mining tasks locally one has to create the cache files by running the code in the preproccesing notebooks.

\subsection{Relation between the pension expenses and the policital alignment of the state's government\label{expenses-wikidata}}

A relation can be assumed between the expenditure on pensions in a state social security system and the political ideology of the state. A left leaning governments usually tend to spend more on social welfare than the right-wing governments. In this section it is shown how this relation can be described by association rules in the spirit of \ref{asocRule} mined from the data published by CSSA and Wikidata. Data from various countries would be more appropriate for mining such relation. The available data are, however, sufficient for a simple demonstration. 

The data cube used\footnote{\href{https://data.cssz.cz/web/otevrena-data/-/vydaje-na-duchody-v-cr}{https://data.cssz.cz/web/otevrena-data/-/vydaje-na-duchody-v-cr}} is published by CSSA and contains records of total annual expenses on particular pensions. From now on it will be denoted as \textit{expenses}. The only measure of the data cube is the expendature amount in CZK. The dimensions of the data cube are the reference period with the granularity of whole years (from 2008 till 2019) and the dimension of the pension kind containing individual pension kind and also aggregated dimension values. For the year 2008 and 2009 and old pension scheme is used so the observations considering these two years were discarded. For the dimension of reference period 10 distinct values remain and the newer pension kind scheme contains also 10 distinct values. That would suggest that 100 observations remain but there are only 94. For the one-off allowance to pensions there are only 4 observations. That probably means that the expenses for this pension kind in the missing years were zero. So the missing observations with the measured value of zero were created manually.

The original data cube was sliced into 10 subcubes (by SPARQL queries) each containing 10 observations. Each subcube is in a separate file in the folder \verb|data/expenses|. In the notebook \verb|expenses.ipynb| each subcube's measures are discretized equifrequently (with 2 and 5 intervals) and equisizeably (with the relative support of 20, 30 and 50 percent) assigning each measurement 5 intervals.

The preproccesing of the Wikidata data set (notebook \verb|wikidata.ipynb|) rested in merging the triples returned by queries \ref{wdextract} and \ref{wdapplies} and removing the triples with predicates \verb|P580| and \verb|P582| as they only served to generate annual triples in the query \ref{wdapplies}.

In the notebook (\verb|expenses-wikidata.ipynb|) of the mining task the two preprocessed data sets were loaded and merged together with the reference period linking triples. From this data set containing \numprint{25494} triples an object of index was created. The rules that should be found are described in plain text as \textit{If in any year the current prime minister belongs to a political party that has a certain political alignment then the annual expenses of a certain pension kind fit into certain interval}. Let's write it as a \textit{pseudo} rule pattern in the context of the available data's structure:
$$
(\langle Czech\_Republic\rangle\hspace{0.4em}headOfGovernment\hspace{0.4em}?headRole) \land (?headRole\hspace{0.4em}person\hspace{0.4em}?person)
$$
$$
\land (?person\hspace{0.4em}partyRole\hspace{0.4em}?partyRole) \land (?partyRole\hspace{0.4em}party\hspace{0.4em}?party)
$$
$$
\land (?party\hspace{0.4em}alignment\hspace{0.4em}AnyConstant) \land (?partyRole\hspace{0.4em}appliesTo\hspace{0.4em}?refPeriod)
$$
$$
\land (?headRole\hspace{0.4em}appliesTo\hspace{0.4em}?refPeriod) \land (?observation\hspace{0.4em}refPeriod\hspace{0.4em}?refPeriod)
$$
$$
\land (?observation\hspace{0.4em}dataSet\hspace{0.4em}AnyConstant) \Rightarrow (?observation\hspace{0.4em}expenses\hspace{0.4em}AnyConstant)
$$

The variable $?headRole$ would bind to binding entitities representing an acting of a specific person in the office just as the variable $?partyRole$ would bind to a binding entitites of memberships of a specific person in a specific political party. The rules yielded from this rule pattern would differ only by the entities at the object positions of the fifth and nineth atom and the head atom. The last body atom with the \verb|qb:dataSet| will ensure that all $?observation$ bindings belong to the same sub cube and thus the commensurability of measures will be preserved. There is no need of an atom stating the pension kind, because all observations in a sub cube share the same one. That way the rule is shorter.

Human tends to write a rule pattern and understand a rule from left to right, from the body to the head, but the algorithm creates the rules in the opposite direction. When writing a rule pattern this fact has to be taken into consideration together with which refining operators are available to the algorithm. The rule pattern above makes perfect sense but the algorithm is not able to generate such rules. Have a look at the sixth body atom. When read from the head, the atom introduces new variable $?partyRole$ while the $?headRole$ variable is still open. The algorithm cannot add a new variable to a rule without closing an open variable in the rule. For this particular rule pattern the problem will be solved by moving the seventh atom to the first position in the body and by switching the positions of the fourth and fifth atom. Also the used algorithm implementation does not allow custom names for variables in a pattern. The variable names have to be single characters ordered alphabeticaly beginning with $?a$ from the rule's head. The definition of the rule pattern object to match the seeked relations in this mining task is shown in listing \ref{alignmentExpensesPattern}:

\begin{figure}[h]
\begin{lstlisting}[language = scala, caption={First pattern definition}, label={alignmentExpensesPattern},captionpos=b, escapeinside={(*@}{@*)}]
val alignmentExpenses: RulePattern = (
    AtomPattern(subject = 'f', predicate = appliesTo, `object` = 'b') &:
    AtomPattern(subject = czURI, predicate = wdProperty(6), `object` = 'f') &:
    AtomPattern(subject = 'f', predicate = wdProperty(6), `object` = 'e') &:
    AtomPattern(subject = 'e', predicate = wdProperty(102), `object` = 'c') &:  
    AtomPattern(subject = 'd', predicate = wdProperty(1387)) &:
    AtomPattern(subject = 'c', predicate = wdProperty(102), `object` = 'd') &:
    AtomPattern(subject = 'c', predicate = appliesTo, `object` = 'b') &:
    AtomPattern(subject = 'a', predicate = cssaRefPeriod, `object` = 'b') &:
    AtomPattern(subject = 'a', predicate = qbdPredicate, `object` = AnyConstant)
    =>:
    AtomPattern(subject = 'a', predicate = expenses)
)
\end{lstlisting}
\end{figure}

This pattern was connected to the mining task definition itself. No minimal support an head coverage thresholds were set so that a maximal number of rules that can be filtered later are found. The maximal rule length set corresponds to the provided rule pattern. The mining task generated \numprint{192} rules\footnote{\href{https://nvkp.github.io/diploma-thesis-code/rulesets/alignmentExpensesTaskRuleset.txt}{https://nvkp.github.io/diploma-thesis-code/rulesets/alignmentExpensesTaskRuleset.txt}}. The rules with a support of 1 were filtered out and the PCA confidence, the standard confidence and lift was computed on the remaining 116 rules\footnote{\href{https://nvkp.github.io/diploma-thesis-code/rulesets/alignmentExpensesTaskRulesetFiltered.txt}{https://nvkp.github.io/diploma-thesis-code/rulesets/alignmentExpensesTaskRulesetFiltered.txt}}. The listing below shows two of them as they are written in the export file.

\begin{figure}[h]
\begin{lstlisting}[language = scala, caption={First pattern's rule sample}, label={alignmentExpensesRulesSample},captionpos=b, escapeinside={(*@}{@*)}]
(?f prfx:appliesToRefPeriod ?b) ^ (wd:Q213 p:P6 ?f) ^ (?f p:P6 ?e) ^ (?e p:P102 ?c) ^ (?d p:P1387 "centre-right") ^ (?c p:P102 ?d) ^ (?c prfx:appliesToRefPeriod ?b) ^ (?a cssa-od:refPeriod ?b) ^ (?a qb:dataSet <expenses-old-age-total>) -> (?a cssa-om:vydaje-na-duchody-opravene-o-zalohy-v-tis-kc <<3.1797095155E8__3.8222294828E8)_ef3_3/3>) | support: 3, headCoverage: 0.005, confidence: 1.0, pcaConfidence: 1.0, lift: 25.0, headConfidence: 0.04, headSize: 600, bodySize: 3, pcaBodySize: 3

(?f prfx:appliesToRefPeriod ?b) ^ (wd:Q213 p:P6 ?f) ^ (?f p:P6 ?e) ^ (?e p:P102 ?c) ^ (?d p:P1387 "centrism") ^ (?c p:P102 ?d) ^ (?c prfx:appliesToRefPeriod ?b) ^ (?a cssa-od:refPeriod ?b) ^ (?a qb:dataSet <expenses-it>) -> (?a cssa-om:vydaje-na-duchody-opravene-o-zalohy-v-tis-kc <<2.488316469E7__2.553204263E7)_ef3_1/3>) | support: 2, headCoverage: 0.0033333333333333335, confidence: 0.6666666666666666, pcaConfidence: 0.6666666666666666, lift: 22.22222222222222, headConfidence: 0.03, headSize: 600, bodySize: 3, pcaBodySize: 3
\end{lstlisting}
\end{figure}

The first rule states that when the government has the center-right political alignment, the total expenses for all types of old age pensions are in the upper third. The second rule predicts the lower third value of expenses on the third degree invalidity pension, when the government's policital alignment is centristic. Note that the head size values are distorted by the performed discretizations. Each of the \numprint{100} observations appears in the head size as many times as there are measure intervals assigned to the head measure predicate. This also distorts the head coverage. Also the lift is over estimated because its denominator works with all \numprint{100} observations when the only observations that matter are that of the sub cube specified in the rule's body.

Quite suprisingly in none of the 116 rules the left alignment is mentioned even though Czech Republic's prime minister from the years 2014 to 2017 was a left leaning politician. Only alignments mentioned are \textit{centre-right} and \textit{centrism}. The only governing party assigned to those values in the covered period is \textit{ANO 2011}\footnote{\href{https://www.wikidata.org/wiki/Q10728124}{https://www.wikidata.org/wiki/Q10728124}}. It seems that the party itself is a sufficient \textit{explanatory variable} for the measure in the data cube. So the pattern was simplified to connect the measured values only to the appropriate party.

\begin{figure}[h]
\begin{lstlisting}[language = scala, caption={Second pattern definition}, label={partyExpensesPattern},captionpos=b, escapeinside={(*@}{@*)}]
val partyExpenses: RulePattern = (
    AtomPattern(subject = 'e', predicate = appliesTo, `object` = 'b') &:
    AtomPattern(subject = czURI, predicate = wdProperty(6), `object` = 'e') &:
    AtomPattern(subject = 'e', predicate = wdProperty(6), `object` = 'd') &:
    AtomPattern(subject = 'd', predicate = wdProperty(102), `object` = 'c') &:  
    AtomPattern(subject = 'c', predicate = wdProperty(102), `object` = AnyConstant) &:
    AtomPattern(subject = 'c', predicate = appliesTo, `object` = 'b') &:
    AtomPattern(subject = 'a', predicate = cssaRefPeriod, `object` = 'b') &:
    AtomPattern(subject = 'a', predicate = qbdPredicate, `object` = AnyConstant)
    =>:
    AtomPattern(subject = 'a', predicate = expenses)
)
\end{lstlisting}
\end{figure}

\numprint{58} rules matching the pattern in \ref{partyExpensesPattern} exceed support of 1. Only party appearing in these rule is the above mentioned \textit{ANO 2011}. It is the latest governing party in the covered period so it could seem that, more than the relation between the pensions expendature and governing party, the rules describe a relation between pensions expendature and time because the measured values are not treated for inflation. There are, however, also rules that predict the lowest of the intervals.

\begin{figure}[h]
\begin{lstlisting}[language = scala, caption={Second pattern's rule sample}, label={alignmentExpensesRulesSample},captionpos=b, escapeinside={(*@}{@*)}]
(?e prfx:appliesToRefPeriod ?b) ^ (wd:Q213 p:P6 ?e) ^ (?e p:P6 ?d) ^ (?d p:P102 ?c) ^ (?c p:P102 wd:Q10728124) ^ (?c prfx:appliesToRefPeriod ?b) ^ (?a cssa-od:refPeriod ?b) ^ (?a qb:dataSet <expenses-old-age-total>) -> (?a cssa-om:vydaje-na-duchody-opravene-o-zalohy-v-tis-kc <<3.1797095155E8__3.8222294828E8)_ef3_3/3>) | support: 3, headCoverage: 0.005, confidence: 1.0, pcaConfidence: 1.0, lift: 25.0, headConfidence: 0.04, headSize: 600, bodySize: 3, pcaBodySize: 3

(?e prfx:appliesToRefPeriod ?b) ^ (wd:Q213 p:P6 ?e) ^ (?e p:P6 ?d) ^ (?d p:P102 ?c) ^ (?c p:P102 wd:Q10728124) ^ (?c prfx:appliesToRefPeriod ?b) ^ (?a cssa-od:refPeriod ?b) ^ (?a qb:dataSet <expenses-it>) -> (?a cssa-om:vydaje-na-duchody-opravene-o-zalohy-v-tis-kc <<2.488316469E7__2.553204263E7)_ef3_1/3>) | support: 2, headCoverage: 0.0033333333333333335, confidence: 0.6666666666666666, pcaConfidence: 0.6666666666666666, lift: 22.22222222222222, headConfidence: 0.03, headSize: 600, bodySize: 3, pcaBodySize: 3
\end{lstlisting}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=\textwidth]{img/expenses.png}
\caption{Expenditure of selected pension kinds over time}
\label{qbstructureimg}
\end{figure}

\subsection{Appending the YAGO Data Set to the CZSO Data Cubes}

In this task the mining were performed over the CZSO's data cube \textit{Job Applicants and Unemployment Rate}, from now on denoted as \textit{JAUR}, and the triples extracted from YAGO data set. The data cube contains dimensions of reference area (89 distinct dimension values constisting of 13 regions without Prague and 76 districts without Prague, meaning there are no data concerning Prague), reference period (years 2005 to 2013) and sex (male, female and total). Each observation in the cube contains multiple measures. All observations are assigned the measures of number of available job applicants (job applicants who have no objective obstacle to taking up a job, eg enrollment in retraining courses or serving a sentence) and unemployment rate. Observations concerning both sexes also contain the measures of all job applicants and number of vacancies.

The data cube had to be sliced along the dimensions of reference area and sex. The dimension of reference area was divided into regions and district. It was considered to divide the dimension of sex by each dimension value, but there is no significant difference between the male and female values\footnote{\href{https://nvkp.github.io/diploma-thesis-code/data/jaur/SexDimension}{https://nvkp.github.io/diploma-thesis-code/data/jaur/SexDimension}}, so the dimension was divided into \textit{total} and \textit{by-sex} part. That makes 4 slices \footnote{\href{https://nvkp.github.io/diploma-thesis-code/data/jaur/slice-queries/}{https://nvkp.github.io/diploma-thesis-code/data/jaur/slice-queries/}} with \numprint{2403} observations ($3 \times 9 \times 89$) and \numprint{6408} measured values in total. All the measured values were discretized\footnote{\href{https://nvkp.github.io/diploma-thesis-code/notebooks/jaur}{https://nvkp.github.io/diploma-thesis-code/notebooks/jaur}} equifrequently with the interval counts of 10, 30, 50 and 100 and equisizeably with the percentages of 1, 2 and 3. The notebook \verb|jaur-yago|\footnote{\href{https://nvkp.github.io/diploma-thesis-code/notebooks/jaur-yago}{https://nvkp.github.io/diploma-thesis-code/notebooks/jaur-yago}} contains the mining itself. The YAGO triples and data cube's triples were merged together with the appropriate reference area linking triples\footnote{\href{https://nvkp.github.io/diploma-thesis-code/data/linking/yagoCZSOLinking.ttl}{https://nvkp.github.io/diploma-thesis-code/data/linking/yagoCZSOLinking.ttl}}.

A separate index (containing all the extracted YAGO triples, the reference area linking triples and only those triples from the \textit{JAUR} cube that belong to the subcube's observations) was created for each subcube. That way the lift measure calculated for the rules mined from the indexes is not distorted because its denominator is not increased by inappropriate observations.

Just as in the previous example, a pattern had to be provided to the mining tasks, that generates rules assigning a particular interval of a measure for observations satisfying the rule's body. In this pattern a variable at the position of object with the predicate of \verb|refArea| appears in an atom that is enforced to bind to triples from the YAGO data set. For the mining task working with this pattern the threshold of maximal rule's length can be declared that corresponds to the number of hops of the extracted YAGO triples (determining the maximal length of the atom \verb|chain| from YAGO) and the number of other atoms in the body and the head atom.

For fininishing the mining task in a reasonable time also a minimal support thresholds has to be declared. The support of the seeked rules corresponds to the number of observations for which the rule is valid. The rules have to contain an atom achoring the observations' variable to a constant of a slice by the \verb|qb:dataSet| predicate to ensure that each rule relates to one and only slice. The slices of the \textit{JAUR} data cube contain a different number of observations, so if a too high minimal support threshold is declared, the potentionally accurate rules from the a smaller slice would be discarded. In \ref{expenses-wikidata} all the slices contain the same number of observations and the whole cube so small that no minimal support threshold did not have to be used. In this mining task the problem was avoided by creating 4 distinct patterns that anchor the observations to each slice. These patterns are then appended to a separate mining task with different minimal support thresholds.

\begin{figure}[h]
\begin{lstlisting}[language = scala, caption={Pattern Definition for the Slice \textit{districts-by-sex}}, label={jaurYagoPatterns},captionpos=b, escapeinside={(*@}{@*)}]
val districtBySexPattern = (
    AtomPattern(subject='b',graph=uri("yago"))&:
    AtomPattern(subject='a',predicate=refArea,`object`='b',graph=uri("czso"))&:
    AtomPattern(subject='a',predicate=qbDataSet,`object`=districtBySexSlice,graph=uri("czso"))
    =>: 
    AtomPattern(subject='a',predicate=oneOfMeasures, graph = uri("czso"))
)
\end{lstlisting}
\end{figure}

The smallest slice is \verb|jaur-regions-total| with only \numprint{117} observations (9 years of 13 regions). Let's assume there is a rule that can be infered from this data that predicts a certain measure value to be in a certain interval given a certain characteristic of the reference area of the observation. Not to describe only one specific region, there have to be at least two regions satisfying the rule. If the rule had the confidence of 1 its support would be \numprint{18} (9~years~$\times$~2~regions). A rule with confidence of 0,5 would have half the support. Less confident rules with support of 9 or higher support would \textit{cover} more regions. A minimal support for each mining task corresponding to single slice can be therefore given as the number of observations in the slice divided by number of observations for a distinct reference area. For the district slices such designated threshold would however not restrict the search space to finish the procedure in a reasonable time so for these two mining tasks with largest number of observations the number was multiplied by 3 (We demand \textit{half confident} rules to concern at least 6 districts).

\begin{figure}[h]
\begin{lstlisting}[language = scala, caption={Mining Task Definition for the Slice \textit{districts-by-sex}}, label={jaurYagoTasks},captionpos=b, escapeinside={(*@}{@*)}]
val districtBySexTask = Amie()
    .addThreshold(Threshold.MinSupport(minSupport(districtBySexSlice)*3))
    .addThreshold(Threshold.MaxRuleLength(6))
    .addConstraint(constantsOnlyAtObject)
    .addPattern(districtBySexPattern)
\end{lstlisting}
\end{figure}

RDFRules API provides a constraint that can be appended to the mining task that eliminates atoms with a constant at the position of subject to be considered during the rule refinement. This shrinks the task's search space and contributes to shorter runtime when such atoms are not relevant for the particular pattern. In \ref{expenses-wikidata} this constraint could not be used since the second atom pattern's subject in the rule pattern was the constant of the Czech Republic's URI. It makes sense to add the constraint now. It makes sense to add the constraint now.

Folows the description of the processing of each mining task's retrieved rule set. The used patterns do not prescribe a structure for each atom in a rule. The length of the rules can vary from 4 to 6 atoms. The patterns do not prevent the refining operators from appending an atom to the rule's body, whose subject variable represents a different observation than the one in the rule's head. That practically introduces a new \textit{unclosed} cube to the rule and invalidates it.

\begin{figure}[h]
\begin{lstlisting}[language = scala, caption={XXX}, label={invalidRuleExample},captionpos=b, escapeinside={(*@}{@*)}]
(?c czso:refPeriod <http://reference.data.gov.uk/id/gregorian-day/2006-12-31>) ^ (?c czso:refArea ?b) ^ (?b <http://schema.org/foundingDate> "2000-11-12") ^ (?a czso:refArea ?b) ^ (?a qb:dataSet <jaur-regions-total>) -> (?a czso:podilNezamestnanych <<9.01__11.47)_ef10_10/10>)
\end{lstlisting}
\end{figure}

Atoms with a new observation variable in those rules are connected through the variable of reference area. They all contain atom with the new variable at the position of subject, reference area dimension URI at the position of predicate and the variable of reference area at the position of object. All those rules were filtered out. Only those rules in the rule set, that have exactly one atom with reference area dimension URI at the position of predicate were kept for further processing.

There is apparently a correlation between the cube's measures (available applicants is a subset of all job applicants, lower unemployment rate corresponds to lower number of vacancies). The algorithm could tend to create evident rules in the sense of \textit{if there is a lower unemployment rate in the area, there is a lower number of applicants registered at the Labor Office}. Not to bother with this kind of rules, the rules with a measure URI at the position of predicate in any atom in the rule's body were filtered out as well. The lift was computed for the remaining rules in the rule sets. All rules the lift value lower than 1 were filtered out. The remaining rules were reduced by the \textit{data coverage pruning} method.

TODO odkazy na výsledky \footnote{\href{https://nvkp.github.io/diploma-thesis-code/rulesets/jaur-yago/}{https://nvkp.github.io/diploma-thesis-code/rulesets/jaur-yago/}}
%In total \numprint{1813} rules\footnote{\href{}{}} from all four rule sets remained.

%The first mining task retrieved \numprint{18677} rules\footnote{\href{https://github.com/nvkp/diploma-thesis-code/blob/master/rulesets/jaurYagoRegionTaskRuleset.txt}{https://github.com/nvkp/diploma-thesis-code/blob/master/rulesets/jaurYagoRegionTaskRuleset.txt}} and the second task's ruleset contains \numprint{193770} rules\footnote{\href{https://github.com/nvkp/diploma-thesis-code/blob/master/rulesets/jaurYagoDistrictTaskRuleset.txt}{https://github.com/nvkp/diploma-thesis-code/blob/master/rulesets/jaurYagoDistrictTaskRuleset.txt}}. 

% jak sem si je poshlukoval

TODO příklady pravidel, ukázat nějaké užitečné a ukázat nějaké vadné

\subsection{Relation Between Measures from Different Data Cubes}

% pensions-salaries

% jake jsou dimenze tech ruznych rezu

%\subsection{Relation between the average salaries and the political alignment of the regional government}

%\subsection{Relation between the average pension amounts and the political alignment of the regional government}

\section{Discussion}