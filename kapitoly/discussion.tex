\chapter{Discussion of the Results\label{discussion}}

The mining task \ref{expenses-wikidata} generated meaningful and interpretable rules and it served as a confirmation, that the considerations of the needed pre-proccessing steps and the sought shape of the rules were correct and it can serve as a demonstration of the possibilities of performing this type of analysis. More diverse rules would be found if the examined data cube contained also the data about other branches of the government spending, not just the pension expenditure.

The problem of commensurability and different ranges of the shared dimensions across the cube caused, that even a quiet massive data cube with multiple hierarchies in the dimensions, such as the \textit{Pensions} cube, had to be cut into tiny subcubes of a couple of observations, which prevents the rules to achieve any significant support in comparison with the association rules mined over transactional tabular data.

For someone who sees such rules for the first time and does not know under what conditions the rules emerged, it would be very difficult to interpret them, especially when the rules concern multiple data cubes and when not all atoms in the rule contain human-readable identifiers (as it is the case with the task \ref{expenses-wikidata}, where the rules contain QIDs and properties in the form of numerical identifiers prefixed by \verb|P|). Transforming those identifiers into a human-readable could be very time consuming depending and the analyst would deprive him or herself of a possibility to merge new sources of triples using those identifiers as well. 

When the rules do not contain atoms from the \textit{unrestrained} knowledge graphs but only use other measures in the same cube or other cubes, the advantage of this approach is not leveraged and e.g. the correlation or regression analysis would do a better job describing the dependence of the measures on each other. 

When no rigid structure of the rules is enforced or when the measures are discretized in an excessive number of ways, an overwhelming number of rules is generated. That happened in the task \ref{jaur-yago} when the number of rules generated for each index was in the tens of thousands. Those rules could not be easily filtered only by confidence or lift, because the rules with top-ranked rules were very similar to each other\footnote{\href{https://nvkp.github.io/diploma-thesis-code/rulesets/jaur-yago/regionTotalLiftComputed.txt}{https://nvkp.github.io/diploma-thesis-code/rulesets/jaur-yago/regionTotalLiftComputed.txt}}. RDFRules framework implements the feature to cluster the rules, so only a few or one rule from each cluster could be kept, but clustering tens of thousands of rules takes hours which makes it impossible to work interactively with the framework. 

So I got into a \textit{vicious circle} where I wanted as small and diverse set of rules as possible and I could not make it diverse because it was not small enough and I could not make it too small either because it would not be diverse enough. The top-k approach was not the solution, because RDFRules implement top-k pruning only by the head coverage, which advantages rules with broader intervals. The data coverage pruning feature of the RDFRules framework was not utilized, because intended to be used in association rule mining for classification\cite{Vanhoof2010} rather than an explorative association rule mining, that this task aimed to be and I wanted the rules to be diverse by the content of the rules, not by the triples that instantiate the rules and to find rules with various chains of properties from the YAGO data set that can determine the measure value in the cube. After tuning the task's parameters and finding the \textit{Golden mean} of the right number of discretizations, the algorithm found few rules that are worth mentioning. One of them is shown in the listing \ref{nitra}.

\begin{figure}[h]
\begin{lstlisting}[language = scala, caption={Rule relating to footballers}, label={nitra},captionpos=b, escapeinside={(*@}{@*)}]
(?d <http://schema.org/memberOf> yago:FC_Nitra) ^ (?d <http://schema.org/birthPlace> ?c) ^ (?b <http://schema.org/containsPlace> ?c) ^ (?a czso:refArea ?b) ^ (?a qb:dataSet <jaur-districts-total>) -> (?a czso:dosazitelniNeumisteniUchazeciOZamestnani <[ 9639.0 ; 25767.0 ]_ef10_10/10>) 

| support: 40, headCoverage: 0.01949317738791423, confidence: 0.6349206349206349, pcaConfidence: 0.6349206349206349, lift: 6.204081632653061, headConfidence: 0.1023391812865497, headSize: 2052, bodySize: 63, pcaBodySize: 63
\end{lstlisting}
\end{figure}

The rule states that in the time span covered by the cube, the districts in which a footballer was born, that has played for the Slovakian club PC Nitra, are associated with the highest number of available job applicants. The body size of the rule is 63 and the cube covers 9 years. It means that there are 7 districts with their natives, that even played for PC Nitra. Out of the 63 observations related to those districts, 40 contained the number of available job applicants in the highest of 10 intervals. Those districts were retrieved by a SPARQL query into the YAGO data set. The list contains districts with a heavy industry tradition, such as Most, Ostrava and Karviná and fairly populous districts such as Olomouc, Brno and Zlín. Both factors can explain the tendency to a higher number of job applicants since it is an absolute value.